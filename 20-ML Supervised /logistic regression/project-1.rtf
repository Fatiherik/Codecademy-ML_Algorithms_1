â€” import codecademylib3_seaborn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load the passenger data
passengers=pd.read_csv('passengers.csv')


# Update sex column to numerical
passengers['Sex']=passengers['Sex'].map({'male':1,'female':2})
# Fill the nan values in the age column

passengers['Age']=passengers['Age'].fillna(passengers['Age'].mean()) 

# Create a first class column
passengers['FirstClass'] = passengers['Pclass'].apply(lambda x: 1 if x == 1 else 0)


# Create a second class column
passengers['SecondClass'] = passengers['Pclass'].apply(lambda x: 1 if x == 2 else 0)

# Select the desired features
features=passengers[['Sex','Age','FirstClass','SecondClass']]
survival=passengers['Survived']

# Perform train, test, split
x_train, x_test, y_train, y_test = train_test_split(features, survival, train_size=0.8, test_size=0.2)

# Scale the feature data so it has mean = 0 and standard deviation = 1

scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)
# Create and train the model

model = LogisticRegression()
model.fit(x_train, y_train)


# Score the model on the train data

print(model.score(x_train,y_train))
# Score the model on the test data
print(model.score(x_test,y_test))

# Analyze the coefficients
print(model.coef_)
#[[ 1.21532723 -0.39276653  0.93851664  0.46418247]] most important feature is 'Sex'

# Sample passenger features
Jack = np.array([0.0,20.0,0.0,0.0])
Rose = np.array([1.0,17.0,1.0,0.0])
Emma = np.array([1.0,23.0,0.0,1.0])

# Combine passenger arrays
combined_arrays = np.array([ Jack, Rose, Emma ])

# Scale the sample passenger features
combined_arrays= scaler.transform(combined_arrays)
#print(combined_arrays)

# Make survival predictions!
print(model.predict(combined_arrays))
print(model.predict_proba(combined_arrays))
